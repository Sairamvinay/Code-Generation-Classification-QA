backend: tensorflow
class_name: Functional
config:
  input_layers:
  - [input_1, 0, 0]
  - [input_2, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 35]
      dtype: float32
      name: input_1
      ragged: false
      sparse: false
    inbound_nodes: []
    name: input_1
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 51]
      dtype: float32
      name: input_2
      ragged: false
      sparse: false
    inbound_nodes: []
    name: input_2
  - class_name: Embedding
    config:
      activity_regularizer: null
      batch_input_shape: !!python/tuple [null, 35]
      dtype: float32
      embeddings_constraint: null
      embeddings_initializer:
        class_name: RandomUniform
        config: {maxval: 0.05, minval: -0.05, seed: null}
      embeddings_regularizer: null
      input_dim: 13741
      input_length: 35
      mask_zero: false
      name: embedding
      output_dim: 100
      trainable: false
    inbound_nodes:
    - - - input_1
        - 0
        - 0
        - {}
    name: embedding
  - class_name: Embedding
    config:
      activity_regularizer: null
      batch_input_shape: !!python/tuple [null, 50]
      dtype: float32
      embeddings_constraint: null
      embeddings_initializer:
        class_name: RandomUniform
        config: {maxval: 0.05, minval: -0.05, seed: null}
      embeddings_regularizer: null
      input_dim: 5001
      input_length: 50
      mask_zero: false
      name: embedding_1
      output_dim: 100
      trainable: false
    inbound_nodes:
    - - - input_2
        - 0
        - 0
        - {}
    name: embedding_1
  - class_name: LSTM
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      dtype: float32
      go_backwards: false
      implementation: 2
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {seed: null}
      kernel_regularizer: null
      name: lstm
      recurrent_activation: sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: false
      return_state: true
      stateful: false
      time_major: false
      trainable: true
      unit_forget_bias: true
      units: 100
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - embedding
        - 0
        - 0
        - {}
    name: lstm
  - class_name: LSTM
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      dtype: float32
      go_backwards: false
      implementation: 2
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {seed: null}
      kernel_regularizer: null
      name: lstm_1
      recurrent_activation: sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: true
      return_state: true
      stateful: false
      time_major: false
      trainable: true
      unit_forget_bias: true
      units: 100
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - embedding_1
        - 0
        - 0
        - &id001 {}
      - - lstm
        - 0
        - 1
        - *id001
      - - lstm
        - 0
        - 2
        - *id001
    name: lstm_1
  - class_name: Dense
    config:
      activation: softmax
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dtype: float32
      kernel_constraint: null
      kernel_initializer:
        class_name: GlorotUniform
        config: {seed: null}
      kernel_regularizer: null
      name: dense
      trainable: true
      units: 5001
      use_bias: true
    inbound_nodes:
    - - - lstm_1
        - 0
        - 0
        - {}
    name: dense
  name: functional_1
  output_layers:
  - [dense, 0, 0]
keras_version: 2.4.0
